# Data Cleaning
df=df.drop_duplicates()
df = df.reset_index()
df['color'].replace('',np.nan,inplace=True)
df.dropna(subset=['color'], inplace=True)
df.reset_index(drop=True,inplace=True)
df[["Il", "Ilce"]] = df["location"].str.split("\n").apply(pd.Series)
df = df.drop('location', axis=1)
df['date'] = pd.to_datetime(df['date'],infer_datetime_format=True,dayfirst=True,format ='%d %B %Y')
df['date'] =  df['date'].dt.strftime('%d/%m/%Y')
df.date.head(5)
df['prices']=df['prices'].astype(str)
df.prices = df.prices.str.replace(' TL', '')
df.prices = df.prices.str.replace('.', '')
df['prices'] = pd.to_numeric(df['prices'])
df['km']=df['km'].astype(str)
df.km = df.km.str.replace(' TL', '')
df.km = df.km.str.replace('.', '')
df['km']=df['km'].astype(int)
df['year']=df['year'].astype(int)
choices = list()
conditions = list()

#Map
for item in harita['features']:
    conditions.append((df["Il"]==item['properties']['name']))
    choices.append(int(item['id']))

#Creating New Column (Km/Median)
df['prices'] = df['prices'].apply(pd.to_numeric, downcast='float', errors='coerce')
df['km_median'] =  df['km'].groupby(df['year']).transform('median')
df['km / median']= df.km/df['km_median']


df.drop('index', axis=1, inplace=True)
df.isnull().sum()
X = copy.deepcopy(df[['year', 'km', 'color', 'model', 'seri', 'km / median']])
y = copy.deepcopy(df[['prices']])
X = pd.get_dummies(data=X, columns=['color', 'year', 'model', 'seri'])#, drop_first=True)
#let us drop stuff we select in order to eliminate multicollinearity
X.drop('year_2022', axis=1)
X.drop('color_Bej', axis=1)
X.drop('model_Taycan', axis=1)
X.drop('seri_Taycan', axis=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)

data = copy.deepcopy(df[['prices','year', 'km', 'color', 'model', 'seri', 'km / median']])

#Price Prediction
from sklearn.ensemble import IsolationForest
iso = IsolationForest(contamination=0.05)
yhat = iso.fit_predict(X_train)
mask = yhat != -1
X_train, y_train = X_train[mask], y_train[mask]
import catboost as cb
train_dataset = cb.Pool(X_train, y_train)
test_dataset = cb.Pool(X_test, y_test)
model = cb.CatBoostRegressor(loss_function='RMSE', eval_metric="RMSE",od_type="Iter")
grid = {'iterations' : [12000],
        'learning_rate': [0.008],
        'depth': [10],
        'l2_leaf_reg': [8],
        'early_stopping_rounds' : [3],
        'grow_policy':['Depthwise']
       }
model.grid_search(grid, train_dataset)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
pred = model.predict(X_test)
rmse = (np.sqrt(mean_squared_error(y_test, pred)))
r2 = r2_score(y_test, pred)
print('Testing performance')
print('RMSE: {:.2f}'.format(rmse))
print('R2: {:.3f}'.format(r2))
